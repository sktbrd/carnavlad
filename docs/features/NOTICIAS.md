# üì∞ Sistema de Not√≠cias - Carnavlad

## üéØ Overview

Sistema completo de scraping e exibi√ß√£o de not√≠cias sobre blocos de carnaval do Rio 2026.

---

## ‚ú® Features

### 1. **Aba de Not√≠cias**
- 5¬™ tab na home page (√≠cone Newspaper)
- Grid responsivo de cards
- Filtros por fonte
- Toggle "Apenas Alertas"
- Atualiza√ß√£o em tempo real

### 2. **Detec√ß√£o Autom√°tica de Alertas**
Sistema identifica palavras-chave em t√≠tulos/resumos:
- **Cancelamento:** cancelado, cancelamento, cancela
- **Adiamento:** adiado, adiamento, adia
- **Mudan√ßas:** mudan√ßa, altera√ß√£o, muda, alterado
- **Avisos:** aten√ß√£o, aviso, importante
- **Altera√ß√µes:** novo local, novo hor√°rio, nova data

### 3. **Scrapers Implementados**
| Fonte | URL | Status |
|-------|-----|--------|
| Di√°rio do Rio | diariodorio.com | ‚úÖ Implementado |
| G1 Carnaval | g1.globo.com/rj/carnaval | ‚úÖ Implementado |
| Veja Rio | vejario.abril.com.br | ‚è≥ A fazer |
| Twitter | x.com/riodejaneiro | ‚è≥ A fazer |
| Instagram | instagram.com/blocosderuario | ‚è≥ A fazer |

---

## üóÑÔ∏è Estrutura do Banco

### Tabela `noticias`

```sql
CREATE TABLE noticias (
  id UUID PRIMARY KEY,
  titulo TEXT NOT NULL,
  resumo TEXT,
  url TEXT UNIQUE NOT NULL,
  fonte TEXT CHECK (fonte IN ('diariodorio', 'g1', 'vejario', 'twitter', 'instagram', 'riotur')),
  imagem_url TEXT,
  publicado_em TIMESTAMPTZ,
  coletado_em TIMESTAMPTZ DEFAULT NOW(),
  tags TEXT[] DEFAULT '{}',
  is_alerta BOOLEAN DEFAULT FALSE,
  bloco_relacionado UUID REFERENCES blocos(id)
);
```

### √çndices
- `idx_noticias_fonte` - Filtro por fonte
- `idx_noticias_publicado` - Ordena√ß√£o por data
- `idx_noticias_alerta` - Busca de alertas
- `idx_noticias_tags` - Busca por tags (GIN)

### RLS Policies
- ‚úÖ Leitura p√∫blica
- ‚ùå Escrita apenas via API route

---

## üöÄ Como Usar

### 1. **Rodar Migration**

No Supabase SQL Editor:
```sql
-- Cole o conte√∫do de:
-- supabase/migrations/007_create_noticias.sql
-- Clique em "Run"
```

### 2. **Testar Scrapers Manualmente**

```bash
# Di√°rio do Rio
node scripts/scrape-diariodorio.js

# G1
node scripts/scrape-g1.js
```

**Sa√≠da:**
```
‚úÖ Encontradas 5 not√≠cias
1. üì∞ Carnaval 2026: Confira programa√ß√£o...
2. üö® ALERTA: Bloco X cancelado...
üíæ Salvo em: data/noticias-diariodorio.json
```

### 3. **Importar para o Supabase**

```bash
# Via script direto (OpenClaw Cron local)
node scripts/import-to-supabase.js all

# Ou fonte espec√≠fica
node scripts/import-to-supabase.js diariodorio
node scripts/import-to-supabase.js g1
```

**Resposta:**
```
‚úÖ IMPORTA√á√ÉO CONCLU√çDA!
   Inseridas: 5
   Duplicadas (puladas): 2
   Erros: 0
   Total coletado: 7
```

### 4. **Ver Not√≠cias no App**

1. Acesse: http://localhost:3456
2. Clique na aba **"Not√≠cias"**
3. Veja as not√≠cias coletadas!

---

## üìä Componente NoticiasView

### Props
Nenhuma (auto-fetch do Supabase)

### Features
- ‚úÖ Grid responsivo (1-3 colunas)
- ‚úÖ Cards com imagem, t√≠tulo, resumo
- ‚úÖ Badge de fonte (cores diferentes)
- ‚úÖ Badge "ALERTA" em vermelho
- ‚úÖ Tags extra√≠das (#cancelamento, #mudanca)
- ‚úÖ Filtro por fonte (dropdown)
- ‚úÖ Toggle "Apenas Alertas"
- ‚úÖ Bot√£o "Atualizar"
- ‚úÖ Link externo para fonte original
- ‚úÖ Data formatada (PT-BR)

### Badge de Cores
```typescript
diariodorio ‚Üí bg-blue-500
g1 ‚Üí bg-red-500
vejario ‚Üí bg-green-500
twitter ‚Üí bg-sky-500
instagram ‚Üí bg-pink-500
riotur ‚Üí bg-purple-500
```

---

## ü§ñ Automa√ß√£o (OpenClaw Cron Local)

**Estrat√©gia:** Usar OpenClaw Cron local ao inv√©s de Vercel Cron.

**Vantagens:**
- ‚úÖ Zero depend√™ncia de Vercel Pro
- ‚úÖ Controle total sobre schedule
- ‚úÖ Execu√ß√£o local (mais r√°pido)
- ‚úÖ Notifica√ß√µes integradas

### Setup Completo

Ver: **[CRON_SETUP.md](./CRON_SETUP.md)**

### Quick Start

```bash
# 1. Testar script
cd /Users/vladnikolaev/carnavlad
node scripts/import-to-supabase.js all

# 2. Configurar cron
chmod +x scripts/setup-cron.sh
./scripts/setup-cron.sh

# 3. Adicionar ao OpenClaw
openclaw cron add < /tmp/scrape-noticias-cron.json

# 4. Verificar
openclaw cron list
```

**Schedule Recomendado:**
```
A cada 2 horas: 0 */2 * * *
Timezone: America/Sao_Paulo
```

---

## üï∑Ô∏è Como os Scrapers Funcionam

### 1. **scrape-diariodorio.js**

**Estrat√©gia 1:** Busca artigos estruturados
```javascript
$('article, .post').each((i, elem) => {
  const titulo = $(elem).find('h1, h2, h3').text()
  const resumo = $(elem).find('p').first().text()
  const imagem = $(elem).find('img').attr('src')
  const url = $(elem).find('a').attr('href')
  // ...
})
```

**Estrat√©gia 2:** Fallback para links
```javascript
$('a').each((i, elem) => {
  if (titulo.includes('bloco') || titulo.includes('carnaval')) {
    // Adiciona como not√≠cia
  }
})
```

### 2. **scrape-g1.js**

**Estrutura G1:**
- `.feed-post` - Container de not√≠cias
- `.feed-post-link` - T√≠tulo
- `.feed-post-body` - Resumo
- `time, .feed-post-datetime` - Data

**Parse de Data Relativa:**
```javascript
if (dataText.includes('hora')) {
  const horasAtras = parseInt(dataText.match(/\d+/)?.[0])
  publicado_em = new Date(Date.now() - horasAtras * 3600000)
}
```

---

## üìù Adicionar Novo Scraper

### Template

```javascript
#!/usr/bin/env node
const axios = require('axios');
const cheerio = require('cheerio');

const TARGET_URL = 'https://site.com.br/carnaval';

async function scrapeNewSource() {
  const { data: html } = await axios.get(TARGET_URL);
  const $ = cheerio.load(html);
  const noticias = [];

  // Extrair not√≠cias
  $('.noticia-selector').each((i, elem) => {
    noticias.push({
      titulo: $(elem).find('.titulo').text(),
      resumo: $(elem).find('.resumo').text(),
      url: $(elem).find('a').attr('href'),
      fonte: 'novaFonte',
      imagem_url: $(elem).find('img').attr('src'),
      publicado_em: new Date().toISOString(),
      coletado_em: new Date().toISOString(),
      tags: extractTags(titulo),
      is_alerta: isAlerta(titulo)
    });
  });

  return noticias;
}

module.exports = { scrapeNewSource };
```

### Integrar no Script de Importa√ß√£o

```javascript
// scripts/import-to-supabase.js
const { scrapeNewSource } = require('./scrape-newsource.js');

// No importToSupabase():
if (source === 'all' || source === 'newsource') {
  console.log('üì∞ Coletando Nova Fonte...');
  const noticias = await scrapeNewSource();
  allNoticias.push(...noticias);
  console.log(`‚úÖ Nova Fonte: ${noticias.length} not√≠cias\n`);
}
```

---

## üö® Troubleshooting

### Erro: "relation noticias does not exist"
**Causa:** Migration n√£o foi rodada  
**Solu√ß√£o:** Rode `007_create_noticias.sql` no Supabase

### Erro: "permission denied for table noticias"
**Causa:** RLS est√° bloqueando  
**Solu√ß√£o:** Certifique-se de que est√° usando a API route (n√£o client-side)

### Scraper retorna array vazio
**Causa:** Site mudou estrutura HTML  
**Solu√ß√£o:** 
1. Inspecione o HTML do site
2. Atualize os seletores no scraper
3. Teste manualmente com `node scripts/scrape-xxx.js`

### CORS error ao fazer scrape
**Causa:** Site bloqueia scrapers  
**Solu√ß√£o:** Use user-agent no axios:
```javascript
headers: {
  'User-Agent': 'Mozilla/5.0 ...'
}
```

---

## üìà M√©tricas

### Performance
- **Tempo de scrape:** ~2-5s por fonte
- **Not√≠cias por fonte:** 5-20 em m√©dia
- **Duplicados:** ~30% (j√° existentes)

### Armazenamento
- **1 not√≠cia:** ~1-2 KB
- **100 not√≠cias:** ~100-200 KB
- **Imagens:** Armazenadas como URLs (n√£o download)

---

## üéØ Roadmap

### ‚úÖ Implementado
- [x] Tabela noticias
- [x] Type Noticia
- [x] Scraper Di√°rio do Rio
- [x] Scraper G1
- [x] API Route /api/scrape
- [x] Componente NoticiasView
- [x] Aba Not√≠cias na home
- [x] Detec√ß√£o de alertas
- [x] Filtros por fonte

### üöß Pr√≥ximos Passos
- [ ] Scraper Veja Rio
- [ ] Scraper Twitter/X
- [ ] Scraper Instagram
- [ ] Vercel Cron auto-scrape
- [ ] Push notifications para alertas
- [ ] Relacionar not√≠cias com blocos espec√≠ficos
- [ ] Dashboard admin para aprovar/rejeitar
- [ ] Scraper de coment√°rios (redes sociais)

---

## ü§ù Contribuindo

### Adicionar Nova Fonte

1. Crie scraper em `scripts/scrape-novafonte.js`
2. Adicione fonte no enum do type `Noticia`
3. Adicione check constraint na migration
4. Integre na API route
5. Adicione cor do badge no componente
6. Teste e envie PR!

---

_√öltima atualiza√ß√£o: 2026-02-13 14:21 GMT-3_
